import os
import sys
from pathlib import Path

# ê°€ìƒí™˜ê²½ ê²½ë¡œ ìœ ì§€
venv_path = Path(__file__).resolve().parent.parent / ".venv" / "Lib" / "site-packages"
sys.path.append(str(venv_path))

from google.genai import Client
from .supabase_client import supabase
from .trend_scout import TrendScout
import yt_dlp
from dotenv import load_dotenv

load_dotenv()

class VideoResearcher:
    def __init__(self):
        self.client = Client(api_key=os.getenv("GEMINI_API_KEY"))
        # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë§¤í•‘ ìœ ì§€
        self.fast_model = "gemini-2.0-flash-lite"
        self.main_model = "gemini-2.0-flash"
        self.heavy_model = "gemini-2.5-flash"

    def get_video_transcript(self, video_id):
        """ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€í•˜ë˜ ëŒ“ê¸€(Comments) ìˆ˜ì§‘ ê¸°ëŠ¥ ì¶”ê°€"""
        ydl_opts = {
            'skip_download': True, 
            'quiet': True,
            'get_comments': True, 
            'max_comments': 30,  # íš¨ìœ¨ì„±ì„ ìœ„í•´ ë² ìŠ¤íŠ¸ ëŒ“ê¸€ 30ê°œ
            'extract_flat': False
        }
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                url = f"https://www.youtube.com/watch?v={video_id}" if len(video_id) == 11 else video_id
                info = ydl.extract_info(url, download=False)
                
                # ì›ë³¸ ë³€ìˆ˜ëª… content ìœ ì§€ + ì•Œê³ ë¦¬ì¦˜ ë¶„ì„ìš© ë°ì´í„° ë³´ê°•
                content = f"Title: {info.get('title')}\n"
                content += f"Description: {info.get('description')}\n"
                content += f"Tags: {info.get('tags', [])}\n"
                
                # ëŒ“ê¸€ ë°ì´í„° ì¶”ê°€ (ì•Œê³ ë¦¬ì¦˜ ë¶„ì„ìš©)
                comments = info.get('comments', [])
                comment_text = "\n".join([f"- {c.get('text')}" for c in comments])
                content += f"\n[Viewer Reactions]\n{comment_text}"
                
                return content
        except Exception as e:
            return f"Error: {str(e)}"

    def analyze_viral_strategy(self, topic, force_update=False):
        """
        force_update=True: ë§¤ë²ˆ ìƒˆë¡œ ë¶„ì„ (ë¡œì§ ìˆ˜ì • ì¤‘ì¼ ë•Œ ì¶”ì²œ)
        force_update=False: ê¸°ì¡´ ë°ì´í„° ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        """

        # 1. ìºì‹œ í™•ì¸ (force_updateê°€ Falseì¼ ë•Œë§Œ ì‘ë™)
        if not force_update:
            cached = supabase.table("research_cache").select("*").eq("topic", topic).execute()
            if cached.data:
                print(f"ğŸ’¡ ê¸°ì¡´ ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {topic}")
                return cached.data[0]["deep_analysis"]

        # 2. ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ (ì—…ê·¸ë ˆì´ë“œëœ ë¡œì§ ê°€ë™)
        print(f"ğŸš€ [ì‹ ê·œ/ê°±ì‹ ] ì•Œê³ ë¦¬ì¦˜ ì •ë°€ ë¶„ì„ ì‹œì‘: {topic}")
        transcript_text = self.get_video_transcript(topic)
        
        # ëª¨ë¸ ì„ íƒ ë¡œì§ (ë°ì´í„° ê¸¸ì´ì— ë”°ë¼)
        selected_model = self.main_model
        if len(transcript_text) > 8000:
            selected_model = self.heavy_model

        print(f"ğŸ“¡ ê°€ë™ ì¤‘ì¸ ëª¨ë¸: {selected_model}")
        
        # [ìˆ˜ì •] ì˜ë¬¸ ë¶„ì„ + í•œê¸€ ìš”ì•½ ì´ì¤‘ êµ¬ì¡° í”„ë¡¬í”„íŠ¸
        prompt_text = (
            f"Analyze the viral patterns and algorithmic success of this video: {topic}\n\n"
            f"Data Source:\n{transcript_text}\n\n"
            "--- INSTRUCTION ---\n"
            "1. First, provide a deep analysis in ENGLISH focusing on:\n"
            "   - Hook Strategy (0-30s) and Retention Pacing.\n"
            "   - Psychological triggers in the title/thumbnail.\n"
            "   - What compliment people gave and why they like it or helped.\n"
            "   - Script Structure: How does the narrative keep viewers hooked? (Analyze the opening, middle-climax, and closing).\n"
            "   - Retention Mechanics: Identify 'Pattern Interrupts' or 'Open Loops' used in the script.\n"
            "   - Psychological Triggers: Why did viewers stay until the end?\n"
            "   - Analyze with Script Engineering and pacing : Open Loop, Pattern Interrupt, High Stakes, Reward\n"
            "2. Then, provide a concise summary in KOREAN (í•œê¸€ ìš”ì•½) including:\n"
            "   - ë°”ì´ëŸ´ í•µì‹¬ í‚¤ì›Œë“œ ë° ì‹œì²­ì ì—´ê´‘ í¬ì¸íŠ¸.\n"
            "   - ìš°ë¦¬ ì±„ë„ ëŒ€ë³¸ ê¸°íš ì‹œ ë°˜ë“œì‹œ ì ìš©í•´ì•¼ í•  ì „ëµ."
            "   - ëŒ€ë³¸ êµ¬ì„±ì˜ ë¹„ë°€: ì‹œì²­ìê°€ ì´íƒˆí•˜ì§€ ëª»í•˜ê²Œ ë§Œë“  ë¬¸ì¥ êµ¬ì¡°ì™€ ì „ê°œ ë°©ì‹.\n"
            "   - í…ì…˜ ìœ ì§€ ê¸°ìˆ : ë¶„ìœ„ê¸°ë¥¼ í™˜ê¸° í•˜ê±°ë‚˜ ëª°ì…ë„ë¥¼ ë†’ì¸ í•µì‹¬ ì¥ì¹˜.\n"
            "   - ìš°ë¦¬ ëŒ€ë³¸ ì ìš©ì : ìš°ë¦¬ê°€ ëŒ€ë³¸ì„ ì“¸ ë•Œ ë³µì œí•´ì•¼ í•  'ë§í•˜ê¸° ë°©ì‹'ê³¼ 'ì •ë³´ ë°°ì¹˜ ìˆœì„œ'.\n"
        )

        analysis_result = ""
        try:
            response = self.client.models.generate_content(
                model=selected_model,
                contents=prompt_text
            )
            analysis_result = response.text
        except Exception as e:
            if "429" in str(e):
                fallback = self.heavy_model
                print(f"âš ï¸ {selected_model} ì¿¼í„° ì´ˆê³¼! {fallback} ì—”ì§„ ì „í™˜.")
                response = self.client.models.generate_content(model=fallback, contents=prompt_text)
                analysis_result = response.text
            else:
                raise e

        # on_conflict='topic'ì„ í†µí•´ URLì´ ê°™ìœ¼ë©´ ë®ì–´ì“°ê¸° í•©ë‹ˆë‹¤.
        if 'analysis_result' in locals() and analysis_result:
            try:
                supabase.table("research_cache").upsert({
                    "topic": topic,
                    "deep_analysis": analysis_result,
                    "raw_transcript": transcript_text,
                    "updated_at": "now()" # ë°ì´í„°ê°€ ì–¸ì œ ê°±ì‹ ë˜ì—ˆëŠ”ì§€ ê¸°ë¡
                }, on_conflict='topic').execute()
                print("âœ… ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ ë°ì´í„°ê°€ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        return analysis_result

if __name__ == "__main__":
    scout = TrendScout()
    researcher = VideoResearcher()

    trends = scout.fetch_trending_videos() 
    
    if isinstance(trends, list):
        for i, trend_item in enumerate(trends, 1):
            print(f"{i}. {trend_item}")
    else:
        print(trends)

    print("\n" + "="*50)
    print("ğŸ‘‰ ë²ˆí˜¸(1-10) ì…ë ¥ ë˜ëŠ” ìœ íŠœë¸Œ URL ë¶™ì—¬ë„£ê¸°:")
    user_input = input("ğŸ‘‰ ì…ë ¥: ").strip()

    target_id = ""
    if "v=" in user_input:
        target_id = user_input.split("v=")[1].split("&")[0]
    elif "youtu.be/" in user_input:
        target_id = user_input.split("/")[-1]
    elif user_input.isdigit() and 1 <= int(user_input) <= len(trends):
        selected_text = trends[int(user_input)-1]
        target_id = selected_text.split(" (Views:")[0]
    else:
        target_id = user_input

    print(f"\nğŸš€ ë¶„ì„ ê³µì • ê°€ë™: {target_id}...")
    result = researcher.analyze_viral_strategy(target_id)
    print("\n" + "="*50)
    print(result)